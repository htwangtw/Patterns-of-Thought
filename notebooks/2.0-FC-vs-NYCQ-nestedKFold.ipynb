{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import sem\n",
    "\n",
    "from nilearn.signal import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loa my modules\n",
    "from src.PMA_SCCA import SCCA\n",
    "from src.utils import load_pkl\n",
    "from src.visualise import *\n",
    "from src.file_io import save_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_path = './data/processed/dict_SCCA_data_prepro_06092017.pkl'\n",
    "# load data\n",
    "dataset = load_pkl(dat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FC_yeo7 = dataset['FC_Yeo7']\n",
    "MRIQ    = dataset['MRIQ']\n",
    "mot     = dataset['Motion_Jenkinson']\n",
    "sex     = dataset['Gender']\n",
    "age     = dataset['Age']\n",
    "confound_raw = np.hstack((mot, sex, age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_folds = 5\n",
    "in_folds = 4\n",
    "para_x, para_y = 9, 9\n",
    "n_selected = 4\n",
    "param_setting = {\n",
    "    'reg_X': np.array(range(1, para_x + 1)) * 0.1,\n",
    "    'reg_Y': np.array(range(1, para_y + 1)) * 0.1,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning confounds\n",
    "\n",
    "We first created the confound matrix according to Smith et al. (2015). The confound variables are motion (Jenkinson), sex, and age. We also created squared confound measures to help account for potentially nonlinear effects of these confounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_confound(RS, COG, confmat):\n",
    "\n",
    "    # regress out confound\n",
    "    z_confound = zscore(confmat)\n",
    "    # squared measures to help account for potentially nonlinear effects of these confounds\n",
    "    z2_confound = z_confound ** 2\n",
    "    conf_mat = np.hstack((z_confound, z2_confound))\n",
    "\n",
    "    # clean signal\n",
    "    RS_clean = clean(np.arctanh(RS), confounds=conf_mat, detrend=False, standardize=False)\n",
    "    COG_clean = clean(zscore(COG), confounds=conf_mat, detrend=False, standardize=False)\n",
    "\n",
    "    return RS_clean, COG_clean, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold CV for parameters/model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KF_out = KFold(n_splits=out_folds, shuffle=True, random_state=42)\n",
    "KF_in = KFold(n_splits=in_folds, shuffle=True, random_state=42)\n",
    "param_grid = ParameterGrid(param_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty selection CV\n",
    "\n",
    "Grid search range, set up inner and outer folds and the parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_grid(para, pred_error, para_fn):\n",
    "    set_text_size(12)\n",
    "\n",
    "    idx = np.argmin(para)\n",
    "    d_idx = np.unravel_index(idx, para.shape)\n",
    "    \n",
    "    title = 'Sparsity Search - Fold {}'.format(i+1)\n",
    "    hm = plt.matshow(para.T, vmin=0, vmax=0.5, cmap=\"inferno_r\")\n",
    "    plt.xticks(range(9), np.array(range(1, 10)) * 0.1)\n",
    "    plt.yticks(range(9), np.array(range(1, 10)) * 0.1)\n",
    "    plt.xlabel('Connectivity')\n",
    "    plt.ylabel('MRIQ')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(hm, label='CV Estimate of Prediction Error')\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle(np.array(d_idx) - 0.5, 1, 1,linewidth=2,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    hm.axes.add_patch(rect)\n",
    "    hm.axes.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    # add prediction error\n",
    "    hm.axes.annotate('Test error:{:.3f}'.format(pred_error), (0,0), (0, -40), \n",
    "                     xycoords='axes fraction', textcoords='offset points', va='top',\n",
    "                     fontstyle='italic', fontsize=10)\n",
    "    plt.savefig(para_fn, dpi=300, tight_layout=True)\n",
    "    plt.close()\n",
    "\n",
    "    return d_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Train-test split 1/5==\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_generr = 1\n",
    "para_search = np.zeros((para_x, para_y, out_folds))\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KF_out.split(FC_yeo7)):\n",
    "    print('==Train-test split {0:}/{1:}=='.format(i + 1, out_folds))\n",
    "    X_discovery, X_test = FC_yeo7[train_idx], FC_yeo7[test_idx]\n",
    "    Y_discovery, Y_test = MRIQ[train_idx], MRIQ[test_idx]\n",
    "    conf_discovery, conf_test = confound_raw[train_idx], confound_raw[test_idx]\n",
    "\n",
    "    para_mean = np.zeros((para_x, para_y))\n",
    "    for j, parameters in enumerate(iter(param_grid)):\n",
    "        para_idx = np.unravel_index(j, para_mean.shape) # (C_x,C_y, K)\n",
    "        model = SCCA(n_components=n_selected, scale=True, n_iter=50,\n",
    "                     penX=parameters['reg_X'], penY=parameters['reg_Y'],\n",
    "                    )\n",
    "        j_model = None\n",
    "        dj_list = []\n",
    "        for k, (train_idx, test_idx) in enumerate(KF_in.split(X_discovery)):\n",
    "\n",
    "            # find best weights for this hyper parameter set\n",
    "            X_train, X_confirm = X_discovery[train_idx], X_discovery[test_idx]\n",
    "            Y_train, Y_confirm = Y_discovery[train_idx], Y_discovery[test_idx]\n",
    "            conf_train, conf_confirm = conf_discovery[train_idx], conf_discovery[test_idx]\n",
    "\n",
    "            X_train_clean, Y_train_clean, confmat_train_clean = clean_confound(\n",
    "                                        X_train, Y_train, conf_train)\n",
    "            X_confirm_clean, Y_confirm_clean, conf_confirm_clean = clean_confound(\n",
    "                            X_confirm, Y_confirm, conf_confirm)\n",
    "\n",
    "            model.fit(X_train_clean, Y_train_clean)\n",
    "            # use the mean variance explained to select the best parameter set\n",
    "            d_orig = (model.cancorr_ ** 2).sum()\n",
    "            d_k = (model.score(X_confirm_clean, Y_confirm_clean) ** 2).sum()\n",
    "            # loss function\n",
    "            error_k = np.abs(d_orig - d_k)\n",
    "            \n",
    "            dj_list.append(error_k)\n",
    "\n",
    "        para_mean[para_idx] = np.mean(dj_list)\n",
    "        \n",
    "    # plot the model search of current fold\n",
    "    para_fn = './reports/revision/cv-fold{:}.png'.format(i + 1)\n",
    "    \n",
    "    d_idx = parameter_grid(para_mean, 0, para_fn)\n",
    "    C = 0.1 * (np.array(d_idx) + 1)\n",
    "    # tune the model and apply test set on the final model\n",
    "    X_discovery_clean, Y_discovery_clean, conf_discovery_clean = clean_confound(X_discovery, Y_discovery, conf_discovery)\n",
    "    X_test_clean, Y_test_clean, conf_test_clean = clean_confound(X_test, Y_test, conf_test)\n",
    "    i_model = SCCA(n_components=n_selected, scale=True, n_iter=50,\n",
    "                     penX=C[0], penY=C[1],\n",
    "                    )\n",
    "    i_model.fit(X_discovery_clean, Y_discovery_clean)\n",
    "    di_orig = (i_model.cancorr_ ** 2).sum()\n",
    "    di = (i_model.score(X_test_clean, Y_test_clean) ** 2).sum()\n",
    "    pred_error = np.abs(di_orig - di)\n",
    "\n",
    "    parameter_grid(para_mean, pred_error, para_fn)\n",
    "    print('Test error:{:}'.format(pred_error))    \n",
    "    \n",
    "    if pred_error < best_generr:\n",
    "        best_generr = pred_error\n",
    "        best_model = copy.deepcopy(i_model)\n",
    "    para_search[..., i] = para_mean\n",
    "\n",
    "# final parameter\n",
    "print('\\nBest parameters based on outer fold results: X-{:}; Y-{:}'.format(best_model.penX, best_model.penY))\n",
    "print('Final test error: {}'.format(best_generr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y, _ = clean_confound(FC_yeo7, MRIQ, confound_raw)\n",
    "best_model.fit(X, Y)\n",
    "joblib.dump(best_model, \n",
    "            './models/SCCA_Yeo7_{:1d}_{:.2f}_{:.2f}.pkl'.format(\n",
    "                best_model.n_components, best_model.penX, best_model.penY))\n",
    "\n",
    "set_text_size(12)\n",
    "u, v = best_model.u, best_model.v\n",
    "\n",
    "figs = show_results(u, v, dataset['Yeo7_ROIs'], dataset['MRIQ_labels'], rank_v=True, sparse=True)\n",
    "\n",
    "write_pdf('./reports/revision/bestModel_confoundclean_collection_nested_{0:1d}_{1:.1f}_{2:.1f}.pdf'.format(\n",
    "                best_model.n_components, best_model.penX, best_model.penY), figs)\n",
    "write_png('./reports/revision/bestModel_component_{:}.png', figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scores, Y_scores, df_z = save_output(dataset, best_model, X, Y, path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_z.to_csv('./data/processed/NYCQ_CCA_score_rev1_{0:1d}_{1:.1f}_{2:.1f}.csv'.format(\n",
    "            best_model.n_components, best_model.penX, best_model.penY))\n",
    "df_z.to_pickle('./data/processed/NYCQ_CCA_score_rev1_{0:1d}_{1:.1f}_{2:.1f}.pkl'.format(\n",
    "            best_model.n_components, best_model.penX, best_model.penY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
