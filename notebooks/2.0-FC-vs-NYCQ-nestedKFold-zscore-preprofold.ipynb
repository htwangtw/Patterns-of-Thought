{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import sem\n",
    "\n",
    "from nilearn.signal import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loa my modules\n",
    "from src.PMA_SCCA import SCCA\n",
    "from src.utils import load_pkl\n",
    "from src.visualise import *\n",
    "from src.file_io import save_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning confounds\n",
    "\n",
    "We first created the confound matrix according to Smith et al. (2015). The confound variables are motion (Jenkinson), sex, and age. We also created squared confound measures to help account for potentially nonlinear effects of these confounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_confound(RS, COG, confmat):\n",
    "    '''\n",
    "    We first created the confound matrix according to Smith et al. (2015). \n",
    "    The confound variables are motion (Jenkinson), sex, and age. \n",
    "    We also created squared confound measures to help account for potentially nonlinear effects of these confounds.\n",
    "    '''\n",
    "\n",
    "    # regress out confound\n",
    "    z_confound = zscore(confmat)\n",
    "    # squared measures to help account for potentially nonlinear effects of these confounds\n",
    "    z2_confound = z_confound ** 2\n",
    "    conf_mat = np.hstack((z_confound, z2_confound))\n",
    "\n",
    "    # clean signal\n",
    "    RS_clean = clean(zscore(RS), confounds=conf_mat, detrend=False, standardize=False)\n",
    "    COG_clean = clean(zscore(COG), confounds=conf_mat, detrend=False, standardize=False)\n",
    "\n",
    "    return RS_clean, COG_clean, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold CV for parameters/model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty selection CV\n",
    "\n",
    "Grid search range, set up inner and outer folds and the parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_grid_scca(reg_X, reg_Y):\n",
    "    '''\n",
    "    reg_X, reg_Y: tuple\n",
    "    (lower limit, upper limit)\n",
    "\n",
    "    n_selected: list\n",
    "    list of component number\n",
    "    '''\n",
    "\n",
    "    param_setting = {\n",
    "        'reg_X': np.arange(reg_X[0], reg_X[1] + 0.1, 0.1),\n",
    "        'reg_Y': np.arange(reg_Y[0], reg_Y[1] + 0.1, 0.1),}\n",
    "    param_grid = ParameterGrid(param_setting)\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def nested_kfold_cv_scca(X, Y, R=None, n_selected=4, out_folds=5, in_folds=5, reg_X=(0.1, 1), reg_Y=(0.1, 1)):\n",
    "    '''\n",
    "    TBC\n",
    "    '''\n",
    "    grid = search_grid_scca(reg_X, reg_Y)\n",
    "    KF_out = KFold(n_splits=out_folds, shuffle=True, random_state=1)\n",
    "    KF_in = KFold(n_splits=in_folds, shuffle=True, random_state=1)\n",
    "    \n",
    "    n_penX = int(reg_X[1] * 10 - reg_X[0] + 1)\n",
    "    n_penY = int(reg_Y[1] * 10 - reg_Y[0] + 1)\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    pred_scores = []\n",
    "    para_search = np.zeros((n_penX, n_penY, out_folds))\n",
    "    for i, (train_idx, test_idx) in enumerate(KF_out.split(X)):\n",
    "        print('Fold {0:}/{1:}'.format(i + 1, out_folds))\n",
    "        X_discovery, X_test = X[train_idx], X[test_idx]\n",
    "        Y_discovery, Y_test = Y[train_idx], Y[test_idx]\n",
    "        R_discovery, R_test = R[train_idx], R[test_idx]\n",
    "        \n",
    "        para_mean_score = np.zeros((n_penX, n_penY))\n",
    "        for j, parameters in enumerate(iter(grid)):\n",
    "            para_idx = np.unravel_index(j, para_mean_score.shape) # (C_x,C_y)\n",
    "            model = SCCA(n_components=1, scale=True, n_iter=100,\n",
    "                         penX=parameters['reg_X'], penY=parameters['reg_Y'],\n",
    "                        )\n",
    "            inner_scores = []\n",
    "            for k, (train_idx, test_idx) in enumerate(KF_in.split(X_discovery)):\n",
    "\n",
    "                # find best weights for this hyper parameter set\n",
    "                X_train, X_confirm = X_discovery[train_idx], X_discovery[test_idx]\n",
    "                Y_train, Y_confirm = Y_discovery[train_idx], Y_discovery[test_idx]\n",
    "                R_train, R_confirm = R_discovery[train_idx], R_discovery[test_idx]\n",
    "                \n",
    "                X_train, Y_train, R_train = clean_confound(X_train, Y_train, R_train)\n",
    "                X_confirm, Y_confirm, R_confirm = clean_confound(X_confirm, Y_confirm, R_confirm)\n",
    "                model.fit(X_train, Y_train)\n",
    "                \n",
    "                pred_ev = model.score(X_confirm, Y_confirm)\n",
    "\n",
    "                inner_scores.append(pred_ev)\n",
    "                    \n",
    "            para_mean_score[para_idx] = np.mean(inner_scores)\n",
    "        \n",
    "        idx = np.argmin(para_mean_score)\n",
    "        d_idx = np.unravel_index(idx, para_mean_score.shape)\n",
    "        C = 0.1 * (np.array(d_idx) + 1)\n",
    "        \n",
    "        para_best_model = SCCA(n_components=n_selected, scale=True, n_iter=100,\n",
    "                         penX=C[0], penY=C[1],\n",
    "                        )\n",
    "        X_discovery, Y_discovery, R_discovery = clean_confound(X_discovery, Y_discovery, R_discovery)\n",
    "        X_test, Y_test, R_test = clean_confound(X_test, Y_test, R_test)\n",
    "        para_best_model.fit(X_discovery, Y_discovery)\n",
    "        pred_ev = para_best_model.score(X_test, Y_test)\n",
    "        pred_scores.append(pred_ev)\n",
    "        \n",
    "        if pred_ev > best_score:\n",
    "            best_score = pred_ev\n",
    "            best_model = copy.deepcopy(para_best_model)\n",
    "            print('\\nNew Best model: \\n {:} components,penalty x: {:}, penalty y: {:}\\nOOS performance: {}'.format(\n",
    "            best_model.n_components, best_model.penX,  best_model.penY,  best_score))\n",
    "        para_search[..., i] = para_mean_score\n",
    "    \n",
    "    # final parameter\n",
    "    print('\\nBest parameters based on outer fold ev results: X-{:}; Y-{:}\\n'.format(\n",
    "            best_model.penX, best_model.penY))\n",
    "    \n",
    "    return (para_search, best_model, pred_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permutate_scca(X, Y, d, model, n_permute=1000):\n",
    "    '''\n",
    "    find the best variates among all components\n",
    "    by calculating the FWE-corrected p-value based on FDR\n",
    "    '''\n",
    "    n_mod_select = model.n_components\n",
    "    permute_cancorr = np.zeros((n_permute, n_mod_select))\n",
    "    np.random.seed(42)\n",
    "    for i in range(n_permute):\n",
    "        # permute the cognitive measures\n",
    "        per_idx = np.random.permutation(Y.shape[0])\n",
    "        cur_y = Y[per_idx, :]\n",
    "        permute_model = copy.deepcopy(model)\n",
    "        permute_model.fit(X, cur_y)\n",
    "        cur_cancorr = permute_model.cancorr_\n",
    "        permute_cancorr[i, :] = cur_cancorr\n",
    "\n",
    "    # calculate the FWE-corrected p value\n",
    "    p_val = (1 + np.sum(d < np.repeat(permute_cancorr[1:, 0:1], n_mod_select, axis=1),0)) / float(n_permute)\n",
    "    results = {\n",
    "        'Component': range(1, n_mod_select + 1),\n",
    "        'P-values': p_val,\n",
    "        'alpah0.05': p_val < 0.05,\n",
    "        'alpah0.01': p_val < 0.01,\n",
    "        'alpah0.001': p_val < 0.001,\n",
    "    }\n",
    "    \n",
    "    df_permute = pd.DataFrame.from_dict(results).set_index('Component')\n",
    "    return df_permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_grid(para, pred_evs, i):\n",
    "    '''\n",
    "    plot the output of the grid search\n",
    "    '''\n",
    "    set_text_size(12)\n",
    "\n",
    "    idx = np.argmax(para)\n",
    "    d_idx = np.unravel_index(idx, para.shape)\n",
    "    \n",
    "    title = 'Sparsity Search - Fold {}'.format(i + 1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    hm = ax.matshow(para.T, vmin=0, vmax=0.25, cmap=\"inferno\")\n",
    "    ax.set_xticklabels(np.array(range(0, 10)) * 0.1)\n",
    "    ax.set_yticklabels(np.array(range(0, 10)) * 0.1)\n",
    "    ax.set_xlabel('Connectivity')\n",
    "    ax.set_ylabel('MRIQ')\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    fig.colorbar(hm, label='CV Estimate of Prediction Error')\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle(np.array(d_idx) - 0.5, 1, 1,linewidth=2,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    # add prediction error\n",
    "    ax.annotate('Test Error:{:.3f}'.format(pred_evs), (0,0), (0, -40), \n",
    "                     xycoords='axes fraction', textcoords='offset points', va='top',\n",
    "                     fontstyle='italic', fontsize=10)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_path = './data/processed/dict_SCCA_data_prepro_06092017.pkl'\n",
    "# load data\n",
    "dataset = load_pkl(dat_path)\n",
    "\n",
    "FC_yeo7 = dataset['FC_Yeo7']\n",
    "MRIQ    = dataset['MRIQ']\n",
    "mot     = dataset['Motion_Jenkinson']\n",
    "sex     = dataset['Gender']\n",
    "age     = dataset['Age']\n",
    "confound_raw = np.hstack((mot, sex, age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, _ = clean_confound(FC_yeo7, MRIQ, confound_raw)\n",
    "out_folds = 5\n",
    "in_folds = 5\n",
    "n_selected = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "\n",
      "New Best model: \n",
      " 4 components,penalty x: 0.8, penalty y: 0.4\n",
      "OOS performance: 0.0204406216325\n",
      "Fold 2/5\n",
      "\n",
      "New Best model: \n",
      " 4 components,penalty x: 0.6, penalty y: 0.4\n",
      "OOS performance: 0.075263016429\n",
      "Fold 3/5\n",
      "Fold 4/5\n",
      "Fold 5/5\n",
      "\n",
      "Best parameters based on outer fold ev results: X-0.6; Y-0.4\n",
      "\n",
      "CPU times: user 4min 1s, sys: 4min 41s, total: 8min 42s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "para_search, best_model, pred_errors = nested_kfold_cv_scca(\n",
    "    FC_yeo7, MRIQ, confound_raw, n_selected, \n",
    "    out_folds=5, in_folds=5, \n",
    "    reg_X=(0.1, 0.9), reg_Y=(0.1, 0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/SCCA_Yeo7_revision_zscore-clean_4_0.60_0.40.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, v = best_model.u, best_model.v\n",
    "joblib.dump(best_model, \n",
    "            './models/SCCA_Yeo7_revision_zscore-clean_{:1d}_{:.2f}_{:.2f}.pkl'.format(\n",
    "                best_model.n_components, best_model.penX, best_model.penY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_text_size(12)\n",
    "figs = show_results(u, v, dataset['Yeo7_ROIs'], dataset['MRIQ_labels'], rank_v=True, sparse=True)\n",
    "write_png('./reports/revision/bestModel_zscore-clean_component_{:}.png', figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scores, Y_scores, df_z = save_output(dataset, best_model, X, Y, path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_z.to_csv('./data/processed/NYCQ_CCA_score_revision_zscore-clean_{0:1d}_{1:.1f}_{2:.1f}.csv'.format(\n",
    "            best_model.n_components, best_model.penX, best_model.penY))\n",
    "df_z.to_pickle('./data/processed/NYCQ_CCA_score_revision_zscore-clean_{0:1d}_{1:.1f}_{2:.1f}.pkl'.format(\n",
    "            best_model.n_components, best_model.penX, best_model.penY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-values</th>\n",
       "      <th>alpah0.001</th>\n",
       "      <th>alpah0.01</th>\n",
       "      <th>alpah0.05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           P-values  alpah0.001  alpah0.01  alpah0.05\n",
       "Component                                            \n",
       "1             0.246       False      False      False\n",
       "2             0.177       False      False      False\n",
       "3             0.218       False      False      False\n",
       "4             0.769       False      False      False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_permute = permutate_scca(X, Y, best_model.cancorr_, best_model, n_permute=1000)\n",
    "df_permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst =[]\n",
    "for i in range(5):\n",
    "    lst.append(parameter_grid(para_search[..., i], pred_errors[i], i))\n",
    "write_png('./reports/revision/grid_zscore-clean_fold_{:}.png', lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
